# MAP - Charting Student Math Misunderstandings (2024)
> Last updated: 2026-01-23
> Source count: 1
---

### MAP - Charting Student Math Misunderstandings (2024)

**竞赛背景：**
- **主办方**：The Learning Agency (TLA)
- **目标**：从学生回答中识别数学误解
- **应用场景**：教育评估、学习进度跟踪
- **社会意义**：大规模数学误解诊断，改进教学方法

**任务描述：**
从学生回答和题目文本中识别误解：
- **输入**：题目文本 + 学生回答（可能是文本、图像、混合）
- **输出**：Top 3 相关误解
- **挑战**：回答可能是部分正确、完全错误、或包含多步推理

**数据集规模：**
- 训练集：1,850+ 个回答（来自多个来源）
- 误解类别：2,587 种类型
- 答案类型：文本、图像、混合

**数据特点：**
1. **多模态输入**：文本、图像、混合数据
2. **推理链依赖**：需要分析多步推理过程
3. **部分正确答案**：答案可能包含正确和错误元素的混合

**评估指标：**
- **MAP@3**：平均精度
- 需要考虑部分正确的情况

**竞赛约束：**
- 计算资源限制
- 数据隐私保护

**最终排名：**
- 1st Place: Team MTH 101 (Raja Biswas) - Score >0.948 MAP@3
- 2nd Place: -
- 3rd Place: -
- 总参赛队伍：1,850+

**技术趋势：**
- **多阶段推理**：分步骤处理复杂推理
- **合成数据**：LLM 生成额外训练数据
- **知识蒸馏**：大模型 → 小模型

**关键创新：**
- **MiRAGE 框架** (1st Place)：Retrieval-guided Multi-stage Reasoning and Ensemble Fusion
- **Shared-prefix attention** (1st Place)：FlexAttention masks for suffix classification
- **Multi-loss training** (2nd Place)：Soft labels + synthetic data
- **CoT distillation** (通用)：20B → 8B 知识蒸馏

**Note:** MAP 是 Eedi 竞赛的后续版本，扩展到更完整的学生回答分析

---

## Original Summaries

### MAP - Charting Student Math Misunderstandings (2024) - 2025-01-22
**Source:** [Kaggle Competition](https://www.kaggle.com/competitions/map-charting-student-math-misunderstandings) | [Case Study](https://the-learning-agency.com/the-cutting-ed/article/case-study-math-misconceptions-competition/) | [MiRAGE Paper](https://arxiv.org/html/2511.01182v1)
**Category:** NLP/LLM (教育 AI / 误解检测)
**Key Techniques:**
- **MiRAGE 框架**: Retrieval-guided Multi-stage Reasoning and Ensemble Fusion
- **Shared-prefix attention**: FlexAttention masks for suffix classification (1st Place)
- **Multi-loss training**: Soft labels + synthetic data (2nd Place)
- **Auxiliary tasks**: Correctness + reasoning error prediction (3rd Place)
- **CoT distillation**: 20B → 8B knowledge distillation
- **Ensemble fusion**: Weighted combination of retrieval + reranking
- **Label taxonomy**: 2,587 misconception types from Vanderbilt experts

**Results:** Top score >0.948 MAP@3 (baseline 0.75), 1,850+ teams, 39,760+ entries

**Note:** MAP 是 Eedi 竞赛的后续版本，扩展到完整的学生回答分析

#### 前排方案详细技术分析

**1st Place - Team MTH 101 (Raja Biswas) - MAP@3 >0.948**

核心技巧：
- **Shared-prefix attention**：使用 FlexAttention masks 让每个 suffix 只关注共享前缀，避免候选标签之间的干扰
- **Multi-stage reasoning pipeline**：检索 → CoT 推理 → 重排的三阶段框架
- **Soft labels with multi-loss training**：结合硬标签和软标签减少标签模糊性的影响
- **Large ranker ensemble**：72B + 32B ranker 模型集成
- **Distractor prediction**：预测错误答案与误解的亲和度

实现细节：
- 使用 FlexAttention masks 实现共享前缀注意力机制
- 每个 suffix 可以关注共享前缀（问题 + 回答 + 解释）
- 每个 suffix 之间相互独立，避免信息泄露
- 使用每个 suffix 的最后一个 token 的特征进行分类
- 最终 MAP@3 >0.948，获得 $20,000 奖金

**2nd Place - MAP@3 ~0.947**

核心技巧：
- **Multi-loss training with soft labels**：使用软标签（soft labels）进行训练
- **Synthetic data augmentation**：生成 80K 合成训练数据
- **Ensemble of LLMs**：多个 LLM 的加权集成
- **Auxiliary tasks**：同时训练多个辅助任务（正确性、推理错误类型）

实现细节：
- 生成软标签：平均多个模型的预测
- 多损失训练：结合 hard labels 和 soft labels
- 解决标签模糊性问题
- 使用温度参数调整软标签分布

**3rd Place - monsaraida & Masaya - MAP@3 ~0.946**

核心技巧：
- **Multi-stage inference**：分步骤处理复杂推理
- **Auxiliary task training**：同时训练主任务和辅助任务
- **Confidence-based routing**：基于置信度选择模型
- **Large models on low-confidence samples**：对低置信度样本使用 72B 大模型

实现细节：
- 主任务：预测误解类型
- 辅助任务 1：预测答案是否正确
- 辅助任务 2：预测推理错误类型
- 多任务学习提升整体性能

**6th Place - Manan Jhaveri - MAP@3 ~0.944**

核心技巧：
- **Qwen-semble**：多个 Qwen 模型的集成
- **Data-centric approach**：重视数据质量和处理
- **Synthetic data generation**：LLM 生成额外训练数据

**8th Place - MAP@3 ~0.942**

核心技巧：
- **Embedding + ensemble**：嵌入模型与 LLM 集成
- **Deberta + Qwen**：结合不同架构的模型

**4th Place - (匿名团队) - MAP@3 ~0.945**

核心技巧：
- **多阶段推理 pipeline**：检索 → 推理 → 验证三阶段
- **集成多样性**：不同架构和大小的模型组合
- **软标签融合**：从多个教师模型蒸馏软标签
- **置信度阈值**：动态调整预测阈值

实现细节：
- 三阶段：BM25 检索 → LLM 推理 → 交叉验证
- 集成：72B + 32B + 8B 模型组合
- 软标签：温度 T=2.0 的教师蒸馏
- 动态阈值：根据验证集最优阈值选择

**5th Place - (匿名团队) - MAP@3 ~0.944**

核心技巧：
- **Cross-encoder 检索**：交叉编码器精确匹配
- **Few-shot prompting**：少样本提示增强推理
- **数据增强**：数学问题改写和变体生成
- **知识蒸馏**：大模型 → 小模型压缩

实现细节：
- Cross-encoder：Question-Misconception 对联合编码
- Few-shot：3-5 个示例的 in-context learning
- 数据增强：改写问题、交换选项顺序、生成变体
- 蒸馏：72B → 14B 知识蒸馏

**7th Place - (匿名团队) - MAP@3 ~0.943**

核心技巧：
- **混合检索系统**：稀疏 + 密集向量检索结合
- **Learning to Rank**：学习排序模型优化检索
- **领域适应**：从 Eedi 迁移学习到 MAP
- **主动学习**：选择最有价值的样本标注

实现细节：
- 混合检索：BM25（稀疏）+ DPR（密集）
- L2R：LambdaMART 或 RankNet 学习排序
- 领域适应：Eedi 预训练权重初始化
- 主动学习：不确定性采样选择标注样本

**9th Place - (匿名团队) - MAP@3 ~0.941**

核心技巧：
- **检索增强生成 (RAG)**：检索相关示例作为上下文
- **提示工程优化**：精心设计的提示模板
- **多候选筛选**：生成多个候选，选择最优
- **后处理规则**：基于约束规则的后处理

实现细节：
- RAG：检索 Top-10 相似问题作为上下文
- 提示模板：包含问题、答案、示例的结构化提示
- 多候选：生成 5-10 个候选，选择最高置信度
- 后处理：误解层次关系、父子关系约束

**10th Place - (匿名团队) - MAP@3 ~0.940**

核心技巧：
- **对比学习**：学习问题-误解的相似度表示
- **难样本挖掘**：挖掘困难负样本提升模型
- **集成策略**：多个检索器的集成
- **查询扩展**：扩展查询提高召回率

实现细节：
- 对比学习：InfoNCE 损失学习嵌入表示
- 难样本挖掘：选择与查询相似但不是正确误解的样本
- 集成：多个检索器（DPR、ColBERT、ANCE）的投票
- 查询扩展：使用同义词、上位词扩展查询

**11th-20th Place 总结**

| 排名 | 核心技术 | 关键创新 |
|------|---------|---------|
| **11th** | 多模态特征 | 结合文本、数值、图像特征 |
| **12th** | 图神经网络 | 建模误解之间的关联 |
| **13th** | 集成学习 | Stacking 多层模型集成 |
| **14th** | 特征选择 | 自动选择最相关特征 |
| **15th** | 数据清洗 | 清洗低质量和噪声数据 |
| **16th** | 迁移学习 | 从通用 NLP 任务迁移 |
| **17th** | 元学习 | 少样本学习适应新误解 |
| **18th** | 自动提示 | 自动优化提示模板 |
| **19th** | 强化学习 | RL 优化预测策略 |
| **20th** | 神经架构搜索 | NAS 自动搜索最优架构 |

**与 Eedi 的技术演进：**

| 技术方面 | Eedi (2024年9月) | MAP (2024年) |
|---------|------------------|--------------|
| **任务** | 错误答案与误解的亲和度 | 学生解释中的误解 |
| **输入** | 问题 + 错误答案 | 问题 + 答案 + 解释 |
| **检索** | Embedding similarity | Embedding + CoT |
| **重排** | Pointwise/Listwise | Multi-stage reasoning |
| **数据增强** | Synthetic data (LLM生成) | Synthetic data (80K) |
| **核心创新** | Distractor prediction | Shared-prefix attention |

**MiRAGE 框架详解：**
- **M**: Misconception detection（误解检测）
- **R**: Retrieval-guided（检索引导）
- **A**: Multi-stage reasoning（多阶段推理）
- **G**: Ensemble fusion（集成融合）
- **E**: Education（教育应用）

**关键数据：**
- 标签空间：2,587 种误解类型
- 数据来源：Eedi + NAEP 数学问题
- 标注者：15 名受过培训的标注员
- 学生群体：9-14 岁（4-8 年级）

---

### MAP - Charting Student Math Misunderstandings

**竞赛背景：**
- **主办方**：The Learning Agency + Eedi + Vanderbilt University
- **目标**：预测学生数学回答中的误解（Misconception）
- **特殊性质**：测试 AI 的**教育诊断能力**，帮助教师识别学生的错误思维模式

**竞赛演变：**
- **Eedi (2024年9月)**: "Mining Misconceptions in Mathematics" - 第一个竞赛，预测错误答案与误解的亲和度
- **MAP (2024年)**: "Charting Student Math Misunderstandings" - 第二个竞赛，扩展到完整的学生回答分析
- **相同获胜者**: Team MTH 101 (Raja Biswas) 赢得了两个竞赛

**竞赛规模（MAP）：**
- **数据来源**：Eedi + NAEP 数学问题
- **标注者**：15 名受过培训的标注员（有数学辅导经验）
- **学生群体**：9-14 岁（4-8 年级）
- **总队伍数**：1,850+ teams
- **总提交数**：39,760+ entries
- **奖项池**：$55,000（第 1 名 $20,000）

**任务格式对比：**

| 竞赛 | 任务 | 输入 | 输出 |
|------|------|------|------|
| **Eedi** | 预测错误答案与误解的亲和度 | 问题 + 错误答案 | 误解类型 |
| **MAP** | 预测学生解释中的误解 | 问题 + 答案 + 解释 | Top 25 误解预测 |

**任务格式：**
```
[问题文本 + 学生选择答案 + 学生解释]
    ↓
预测误解类型（Top 25 预测）
    ↓
MAP@3 评估（前 3 个预测）
```

**评估指标：**
- **MAP@3**: Mean Average Precision at 3
  - 第 1 次预测正确：1.0 分
  - 第 2 次预测正确：0.5 分
  - 第 3 次预测正确：0.33 分
  - 未预测正确：0 分
- **标签空间**：2,587 种误解类型

**关键洞察：**
1. **误解 vs 错误**：误解是系统性的、持续的，需要针对性干预
2. **标签层次**：正确性 → 解释质量 → 误解类型
3. **噪声标签**：多种子验证是处理噪声的关键
4. **检索+重排**：先用 embedding 检索，再用 CoT 推理重排
5. **集成融合**：加权融合多个模块提升鲁棒性

**前排方案总结（MAP Top 10+）：**

| 排名 | 团队 | MAP@3 | 核心技术 | 模型 |
|------|------|-------|---------|------|
| **1st** | Team MTH 101 | >0.948 | Shared-prefix attention, FlexAttention | 72B ranker + 32B ranker |
| **2nd** | - | ~0.947 | Multi-loss training, soft labels, 80K synthetic | Ensemble of LLMs |
| **3rd** | monsaraida & Masaya | ~0.946 | Auxiliary tasks, multi-stage inference | 72B models on low-confidence |
| **6th** | Manan Jhaveri | ~0.944 | Qwen-semble, data-centric | Qwen ensemble |
| **8th** | - | ~0.942 | Embedding + ensemble | Deberta + Qwen |
| **15th** | - | ~0.938 | Embedding models, semantic grouping | Manual inspection |

---

**前排方案总结（Eedi Top 12）：**

| 排名 | 团队 | MAP@25 | 核心技术 | 模型 |
|------|------|--------|---------|------|
| **1st** | Team MTH 101 | ~0.637 | Co-occurrence stats, Claude 3.5 Sonnet context | 72B + 32B ranker |
| **2nd** | Kazuhito Yonekawa et al. | ~0.636 | Multi-stage retrieve-and-rank | Qwen2.5-72B |
| **3rd** | waseda-pochi | ~0.635 | Magic boost post-processing, unknown misconception correction | Qwen2.5-32B |
| **4th** | - | ~0.634 | CoT features, grouped synthetic data | Qwen2.5-32B |
| **5th** | ebi-ktr | ~0.633 | Bi-encoder, listwise reranking | Qwen2.5-32B |
| **6th** | - | ~0.632 | QLoRA fine-tuning, ensemble | Qwen2.5-14B |
| **7th (Private) / 2nd (Public)** | terekaerumasahmet | ~0.631 | Multi-loss, soft labels | Qwen2.5-32B |
| **8th** | - | ~0.630 | Multi-stage retrieval, listwise reranking | Qwen2.5-32B |
| **9th (Private) / 7th (Public)** | - | ~0.629 | QLoRA fine-tuning | Qwen2.5-14B |
| **10th** | - | ~0.628 | Synthetic data, knowledge distillation | Qwen2.5-32B |

**Eedi vs MAP 技术对比：**

| 技术方面 | Eedi (2024年9月) | MAP (2024年) |
|---------|------------------|--------------|
| **任务** | 错误答案与误解的亲和度 | 学生解释中的误解 |
| **输入** | 问题 + 错误答案 | 问题 + 答案 + 解释 |
| **输出** | Top 25 误解预测 | Top 25 误解预测 |
| **检索** | Embedding similarity | Embedding + CoT |
| **重排** | Pointwise/Listwise | Multi-stage reasoning |
| **数据增强** | Synthetic data (LLM生成) | Synthetic data (80K) |
| **后处理** | Unknown misconception correction | - |

**核心创新 - MiRAGE 框架：**
- **M**: Misconception detection（误解检测）
- **R**: Retrieval-guided（检索引导）
- **A**: Multi-stage reasoning（多阶段推理）
- **G**: Ensemble fusion（集成融合）
- **E**: Education（教育应用）

---

