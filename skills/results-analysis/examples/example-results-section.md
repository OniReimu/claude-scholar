# Results Section Example

论文 Results 部分的完整示例，展示如何呈现实验结果。

---

## Results

### 主要发现概述

我们在四个基准数据集上评估了提出的方法，并与两个强基线方法进行了对比。实验结果表明，我们的方法在所有数据集上均取得了最优性能，平均准确率达到 93.9%，相比最强基线 BERT-base 提升 1.7 个百分点。此外，我们的方法在训练效率上也表现出色，训练时间减少 38.8%。消融实验验证了各组件的有效性，其中 Layer Normalization 和 Attention 机制对性能提升贡献最大。

### 实验设置

我们在四个文本分类数据集上进行实验：IMDB（电影评论，50K 样本），SST-2（情感分析，67K 样本），AG News（新闻分类，120K 样本），和 DBpedia（知识图谱，560K 样本）。所有实验使用相同的训练设置：batch size 32，AdamW 优化器，学习率 1e-4，早停策略（patience=3）。为确保结果可重现，我们使用固定的随机种子集合 {42, 123, 456, 789, 1024} 进行 5 次独立运行，并报告均值和标准差。所有实验在 4 块 NVIDIA V100 GPU 上进行，总计约 12 小时训练时间。详细的超参数设置见 Appendix A。

### 性能对比

表 1 展示了三个模型在四个数据集上的性能对比。我们的方法在所有数据集上均优于基线方法，平均准确率达到 93.9%，相比 Baseline LSTM 提升 6.1 个百分点，相比 BERT-base 提升 1.7 个百分点。特别值得注意的是，在小数据集 IMDB 上，我们的方法相比 BERT-base 提升了 2.2 个百分点，这表明我们的方法在数据量较少时表现更好。

**表 1**: 不同模型在四个数据集上的准确率对比（%）。数值为 5 次运行的均值 ± 标准差。加粗表示最优结果。

| 模型 | IMDB | SST-2 | AG News | DBpedia | 平均 |
|------|------|-------|---------|---------|------|
| Baseline LSTM | 86.2 ± 1.8 | 84.5 ± 2.1 | 88.3 ± 1.5 | 92.1 ± 1.2 | 87.8 |
| BERT-base | 91.3 ± 1.2 | 89.7 ± 1.5 | 92.5 ± 1.1 | 95.3 ± 0.9 | 92.2 |
| **Our Method** | **93.5 ± 1.3** | **91.2 ± 1.4** | **94.1 ± 1.2** | **96.8 ± 0.8** | **93.9** |

为了验证性能提升的统计显著性，我们使用配对样本 t-test 进行检验。在进行参数检验前，我们使用 Shapiro-Wilk 检验验证了数据的正态性（所有组 p > 0.05），使用 Levene 检验验证了方差齐性（F = 1.23, p = 0.31）。结果表明，我们的方法显著优于 Baseline LSTM（t(8) = 5.67, p < 0.001, Cohen's d = 2.13）和 BERT-base（t(8) = 3.21, p = 0.012, Cohen's d = 1.05）。经过 Bonferroni 校正后（α' = 0.017），差异仍然显著。效应量分析表明，性能提升不仅统计显著，而且实际差异很大（Cohen's d > 1.0）。

图 1 展示了三个模型的训练曲线。可以观察到，我们的方法在前 10 个 epoch 内快速收敛，而 BERT-base 需要 12 个 epoch 才能达到相似的性能。这表明我们的方法不仅性能更好，而且训练效率更高。误差带（阴影区域）表示 5 次运行的标准差，可以看出我们的方法在训练过程中保持稳定，变异性较小。

### 消融实验

为了验证各组件对性能的贡献，我们进行了消融实验。表 2 展示了移除不同组件后的性能变化。可以观察到，所有组件都对性能有正向贡献，其中 Layer Normalization 最为重要，移除后性能下降 2.3 个百分点。Attention 机制次之，移除后性能下降 1.9 个百分点。Positional Encoding 的贡献相对较小，但仍然不可或缺，移除后性能下降 1.0 个百分点。

**表 2**: 消融实验结果。Δ 表示相对完整模型的性能变化。

| 配置 | IMDB | SST-2 | AG News | DBpedia | 平均 | Δ |
|------|------|-------|---------|---------|------|---|
| Full Model | 93.5 | 91.2 | 94.1 | 96.8 | 93.9 | - |
| w/o Attention | 91.2 | 89.5 | 92.3 | 95.1 | 92.0 | -1.9 |
| w/o Positional Encoding | 92.1 | 90.1 | 93.2 | 96.0 | 92.9 | -1.0 |
| w/o Layer Norm | 90.8 | 88.9 | 91.8 | 94.8 | 91.6 | -2.3 |

这些结果验证了我们设计的合理性：Layer Normalization 稳定了训练过程，Attention 机制捕获了长距离依赖，Positional Encoding 保留了序列信息。三者协同工作，共同实现了性能提升。

### 超参数敏感性分析

我们研究了关键超参数 learning rate 对性能的影响。图 2 展示了不同 learning rate 下的平均准确率。可以观察到，最优 learning rate 为 1e-4，过小（1e-5）会导致收敛慢、性能次优，过大（1e-3）会导致训练不稳定、性能下降。我们的方法对 learning rate 的选择相对鲁棒，在 5e-5 到 5e-4 的范围内都能取得较好的性能（> 92%）。

### 训练效率分析

表 3 对比了三个模型的训练效率。我们的方法在训练时间上优于 BERT-base，减少了 38.8% 的训练时间和 GPU 小时。这主要得益于更高效的模型架构和更快的收敛速度。虽然我们的方法比 Baseline LSTM 慢，但考虑到性能提升（+6.1%），这一代价是可以接受的。

**表 3**: 训练效率对比。

| 模型 | 训练时间 | 收敛 Epoch | GPU 小时 | 参数量 |
|------|----------|-----------|----------|--------|
| Baseline LSTM | 2.5h | 15 | 10 | 5M |
| BERT-base | 8.5h | 12 | 34 | 110M |
| Our Method | 5.2h | 10 | 20.8 | 45M |

### 定性分析

为了更好地理解我们的方法，我们对一些典型样本进行了定性分析。图 3 展示了注意力权重的可视化，可以看出我们的方法能够准确地关注到关键词汇（如"excellent", "terrible"），这解释了为什么我们的方法在情感分析任务上表现出色。此外，我们发现我们的方法对否定词（如"not good"）的处理更加准确，这可能是性能提升的另一个原因。详细的案例分析见 Appendix B。

---

## 写作要点说明

### 1. 结构清晰

- **概述** → **实验设置** → **性能对比** → **消融实验** → **额外分析** → **定性分析**
- 每个部分有明确的目的和主题
- 逻辑流畅，层层递进

### 2. 引导读者观察

- ✅ "可以观察到..."
- ✅ "特别值得注意的是..."
- ✅ "这表明..."
- ✅ "这解释了..."

### 3. 完整的统计信息

- ✅ 均值 ± 标准差
- ✅ 实验重复次数（5 次）
- ✅ 随机种子
- ✅ 统计检验方法（t-test）
- ✅ 预先检验（正态性、方差齐性）
- ✅ p-value 和效应量
- ✅ 多重比较校正

### 4. 表格和图表配合

- 表格展示精确数值
- 图表展示趋势和分布
- Caption 独立完整
- 文本解释关键观察

### 5. 客观描述

- ✅ "我们的方法在所有数据集上均优于基线方法"
- ❌ "我们的方法是最好的"
- ✅ "在我们测试的四个数据集上"
- ❌ "在所有情况下"

### 6. 诚实报告

- 报告所有实验结果
- 承认局限性（如只在英文数据集上测试）
- 说明实验设置和假设
- 提供足够的细节以便重现

---

## 常用句式

### 引入实验
- "为了验证 [假设]，我们进行了 [实验]"
- "表 X 展示了 [实验] 的结果"
- "我们首先评估了 [方法] 在 [数据集] 上的性能"

### 描述结果
- "我们的方法达到了 [数值]，优于 [基线] 的 [数值]"
- "图 X 展示了 [现象]。可以观察到 [关键观察]"
- "与 [基线] 相比，我们的方法在 [指标] 上提升了 [百分比]"

### 统计显著性
- "这一差异在统计上显著（p < 0.01）"
- "t-test 显示两组之间存在显著差异（p = 0.003）"
- "经过 Bonferroni 校正后，差异仍然显著"

### 消融实验
- "为了验证 [组件] 的贡献，我们进行了消融实验"
- "移除 [组件] 后，性能下降了 [数值]，这表明 [结论]"
- "表 X 展示了各组件的贡献"

### 解释和分析
- "这表明 [解释]"
- "这可能是因为 [原因]"
- "这解释了为什么 [现象]"
- "这验证了我们的假设，即 [假设]"
